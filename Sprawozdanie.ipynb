{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2015770",
   "metadata": {},
   "source": [
    "\n",
    "# Wstęp\n",
    "Problemem, który staraliśmy się rozwiązać przy pomocy Sztucznej Inteligencji było rozpoznawanie ręcznie pisanych cyfr.\n",
    " W tym celu skorzystaliśmy z data setu <a href=\"http://yann.lecun.com/exdb/mnist/\">MINST</a>, który oferował 60,000  przykładów treningowych oraz 10,000 przykładów testowych.Pliki zawarte w data secie to monochromatyczne cyfry o rozmiarach 28x28 pikseli, gdzie na każdy piksel przypada jeden bajt informacji o kolorze (0-255) co daje około 55MB danych nie wliczając etykiet.\n",
    "Wartości pikseli są w dalszym etapie jednak normalizowane i przyjmują wartości -1 dla dolnej połowy zakresu i 1 dla górnej połowy zakresu.Do realizacji zadania zastosowaliśmy trzy metody: <i>SVM,Sieć Neuronowa oraz SoftMax Regression</i> i w dalszej części sprawozdania opisane zostały matematyczne podstawy działania tych metod i wyniki zastosowania ich do problemu klasyfikacji.\n",
    "</p>\n",
    "\n",
    "# Opisy i wyniki działania metod\n",
    "\n",
    "## SVM\n",
    "### Opis algorytmu SVM\n",
    "\n",
    "Celem algorytmu SVM jest znalezienie takich parametrów $w , b$, na podstawie których algorytm będzie poprawnie klasyfikował binarnie dane według funkcji decyzyjnej $h(x) = wx+b$ z jak największym marginesem od powierzchni decyzyjnej, margines ten dla $i$-tego elementu wektora danych można zdefiniować jako $$ \\gamma^{(i)} = y^{(i)} (w^Tx^{(i)} + b)  \\tag{1} $$ i margines dla całego zestawu danych jako $$ \n",
    "\\gamma = min \\ \\gamma^{(i)} \n",
    "$$\n",
    "Cel optymalizacji można sformułować więc jako $$ max \\ \\gamma $$ pod warunkiem $$ \\forall_{i} \\gamma^{(i)} \\ge \\gamma $$ Należy wziąć również pod uwagę, że w sformułowanym powyżej problemie zwiększenie $w$ i $b$ o stałą zwiększałoby również margines, czemu zaradzić można poprzez maksymalizowanie marginesu podzielonego przez normę wekotra $w$, dzięki temu możemy dowolnie zmieniać $w, b$ (więc również ustalić dowolną poszukiwana wartość $\\gamma$), co prowadzi do kolejnego uproszczenia problemu poprzez ustawienie $\\gamma = 1$. Otrzymujemy więc: $$ max \\ \\frac{1}{||w||} \\ \\Leftrightarrow  min \\ \\frac{1}{2} ||w||^2 \\tag{2} $$\n",
    "pod warunkiem $$ \\forall_{i} \\gamma^{(i)} \\ge 1 \\tag{3} $$\n",
    "\n",
    "Na podstawie [1] $w$ można przedstawić jako kombinację liniową $w =\\sum^{i}\\alpha_i y_i x_i$ pod warunkiem $\\sum^i \\alpha_i y_i = 0$, więc cel optymalizacji można przepisać jako:\n",
    "$$ min \\  \\frac{1}{2} \\sum^N_{i=1}\\sum^N_{j=1}y_i y_j (x_i \\cdot x_j) \\alpha_i \\alpha_j - \\sum^N_{i=1}\\alpha_i \\tag{4} $$ pod warunkiem\n",
    "$$ \\forall_i \\alpha_i \\ge0 \\ , \\quad \\sum^N_{i=1}y_i\\alpha_i = 0 \\tag{5}  $$\n",
    "\n",
    "W celu umożliwienia algorytmowi radzenie sobie z danymi których nie da się odseparować wprowadzane jest kolejne ograniczenie na $\\alpha$, $$ \\alpha \\le C $$ gdzie $C$ jest parametrem umożliwiającym nie poprawną klasyfikację przypadków w celu osiągnięcia poprawnego marginesu. \n",
    "\n",
    "Chcąc uzyskać nieliniowe powierzchnie decyzyjne można użyć funkcji jądrowych (kernel functions) mierzących podobieństwo / dystans między dwoma wektorami cech. Funkcje jądrowe efektywnie realizują podniesienie wymiarowości danych wejściowych bez konieczności robienia tego explicite. Finalnie cel optymalizacji wygląda następująco :\n",
    "$$ min \\  \\frac{1}{2} \\sum^N_{i=1}\\sum^N_{j=1}y_i y_j K(x_i , x_j) \\alpha_i \\alpha_j - \\sum^N_{i=1}\\alpha_i \\tag{6} $$ pod warunkiem\n",
    "$$ \\forall_i \\ 0 \\le \\alpha_i \\le C \\ , \\quad \\sum^N_{i=1}y_i\\alpha_i = 0 \\tag{7} $$\n",
    "gdzie K jest funkcją jądrową.\n",
    "\n",
    "A funkcję decyzyjną można sformułować jako :\n",
    "$$\n",
    "h(x) = \\sum^N_{i=1}y_i\\alpha_i K(x_i, x) + b \\tag{8}\n",
    "$$\n",
    "\n",
    "W oparciu o [2] można stwierdzić, że problem optymalizacyjny jest rozwiązany wtedy, gdy spełnione są Warunki Karusha–Kuhna–Tuckera (KKT) dla każdego $\\alpha$. Warnuki KKT dla tego problemu to :\n",
    "$$ \\alpha_i = 0 \\Leftrightarrow y_i h(x_i) \\ge 1 $$\n",
    "$$ 0 < \\alpha_i < C \\Leftrightarrow y_i h(x_i)= 1 $$\n",
    "$$ \\alpha_i = C \\Leftrightarrow  y_i h(x_i) \\le 1 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69733aa0",
   "metadata": {},
   "source": [
    "### Algorytm SMO\n",
    "\n",
    "Algorytm SMO w każdej iteracji pętli wybiera najmniejszy możliwy do rozwiązania problem optymalizacyjny - wybiera dwa $\\alpha$ i znajduje wartość optymalną dla obu. \n",
    "\n",
    "\n",
    "#### Obliczanie nowych wartości $\\alpha$ i $b$\n",
    "Z wybranych $\\alpha_i, \\alpha_j$ jako pierwsza będzie ustalana wartość dla $\\alpha_j$. Najpierw należy obliczyć w jakich granicach powinna mieścić się ta wartość, tak aby warunki $(7)$ były spełnione.\n",
    "\n",
    "Jeśli $y_j = y_i$ :\n",
    "$$  L = max(0, \\alpha_2-\\alpha_1), \\quad H = min(C, C+ \\alpha_2 - \\alpha_1)  \\tag{9}$$\n",
    "\n",
    "W przeciwnym wypadku :\n",
    "$$  L = max(0, \\alpha_2+\\alpha_1 - C), \\quad H = min(C, C+ \\alpha_2 + \\alpha_1)  \\tag{10}$$\n",
    "\n",
    "Następnie minimalizujemy funkcję $(6)$ po $\\alpha_i, \\alpha_j$:\n",
    "\n",
    "$$ min _{\\alpha_j, \\alpha_i} \\  \\frac{1}{2}K(x_j, x_j)\\alpha_j + \\frac{1}{2}K(x_i, x_i)\\alpha_i + \\frac{1}{2}y_j\\alpha_j\\sum_{k \\neq j} y_k\\alpha_k K(x_j, x_k) + \\frac{1}{2}y_i\\alpha_i\\sum_{k \\neq i} y_k\\alpha_k K(x_i, x_k) - \\alpha_j - \\alpha_j   \\tag{11}$$\n",
    "\n",
    "Otrzymaliśmy równanie kwadratowe dwóch zmiennych postaci $$ Ax^2 + By^2 + Cx + Dy + Exy + F $$ które ma minimum $$ x_m = \\frac{DE - 2BC}{\\eta}  \\tag{12} $$ wtedy i tylko wtedy gdy $$ 4AB - E^2 = \\eta > 0  \\tag{13}$$\n",
    "\n",
    "Jeśli $$ \\eta = 2K(x_i, x_j) - K(x_j, x_j) - K(x_i, x_i) > 0  \\tag{14} $$ $\\alpha_j$ ustawiane jest  według $(12)$ na $$\\alpha_j += \\frac{y_j(E_i - E_j)}{\\eta} \\tag{15}$$, gdzie $$ E_i = h(x_i) - y_i \\tag{16} $$ i ewentualnie przycinane do granic ustaloych w $(9)$ lub $(10)$. \n",
    "\n",
    "Jeśli zaś $\\eta \\le 0$ funkcja celu jest ewaluowana w górnym i dolnym ograniczeniu i $\\alpha_j$ jest ustawiane na ten koniec przedziału w którym ma ona mniejszą wartosć\n",
    "\n",
    "Po ustawieniu $\\alpha_j$ sprawdzane jest czy poczyniona została jakakolwiek znacząca zmiana (większa od pewnej ustalonej tolerancji), jeśli tak, to $\\alpha_i$ ustawiane jest na $$ \\alpha_1 += y_1y_2(\\alpha_{2, old} - \\alpha_{2, new}) \\tag{17}$$ w celu spełnienia ograniczeń.\n",
    "\n",
    "Po zmianie wartości $\\alpha$ należy wyliczyć nowe $b$, tak aby warunki KKT były spełnione.\n",
    "\n",
    "Jeśli $0 \\le \\alpha_i \\le C$\n",
    "$$ b = b_1 = b - E_i -y^{(i)}(\\alpha_{i, new} - \\alpha_{i, old}) \\langle x^{(i)}, x^{(i)} \\rangle -y^{(j)}(\\alpha_{j, new} - \\alpha_{j, old}) K( x^{(i)}, x^{(j)}) \\tag{18}$$\n",
    "Jeśli $0 \\le \\alpha_j \\le C$\n",
    "$$ b= b_2 = b - E_j -y^{(i)}(\\alpha_{i, new} - \\alpha_{i, old}) K(x^{(i)}, x^{(j)}) -y^{(j)}(\\alpha_{j, new} - \\alpha_{j, old}) K(x^{(j)}, x^{(j)}) \\tag{19} $$\n",
    "Jeśli $0 \\le \\alpha_j \\le C$ i  $0 \\le \\alpha_i \\le C$, wtedy $b_1 = b_2$\n",
    "\n",
    "Jeśli zaś oba $\\alpha_i, \\alpha_j$ są ograniczone wtedy wszystkie $b$ pomiędzy $b_1$ i $b_2$ będą spełniały warunki KKT, więc wybieramy \n",
    "$$\n",
    "b = \\frac{b_1 + b_2}{2} \\tag{20}\n",
    "$$\n",
    "\n",
    "#### Wybór $\\alpha$ do optymalizacji\n",
    "Podczas pracy algorytmu w pamięci przechowywane są zbiory $\\alpha$ - nieograniczonych $( 0 < \\alpha_i < C)$ i ograniczonych  $(\\alpha_i = C \\lor \\alpha_i = 0)$. \n",
    "\n",
    "##### Wybór pierwszej wartości\n",
    "Algorytm na przemian wykonuje następujące kroki dopóki możliwe jest wykonanie jakiejkolwiek znaczącej zmiany:\n",
    "\n",
    "1) Iteruje po wszystkich elementach zbioru treningowego i z podejmuje próbę optymalizacji $j$-tego elementu jeśli $\\alpha_j$ narusza warunki KKT.\n",
    "\n",
    "2) Iteruje po wszystkich nieograniczonych $\\alpha$ podejmując próby optymalizacji  $j$-tego elementu jeśli $\\alpha_j$ narusza warunki KKT.\n",
    "\n",
    "Algorytm powtarza krok 2) dopóki rezultatem jego jest znacząca zmiana chociaż jednej pary $\\alpha$, gdyż to właśnie nieograniczone $\\alpha$ mają największe prawdopodobieństwo naruszania warunków KKT.\n",
    "Spełnienie warunków KKT jest sprawdzane do pewnej tolerancji.\n",
    "\n",
    "##### Wybór drugiej wartości\n",
    "\n",
    "Po wybraniu pierwszego $\\alpha$ drugie musi zostać wybrane w taki sposób, aby maksymalizować zmianę w funkcji celu. Najpierw podejmowana jest próba wyboru $\\alpha_i$ według następującej heurystyki : chcemy żeby moduł z licznika z równania $(15)$ był jak największy, więc jeśli $E_j < 0$ wybieramy $\\alpha_i$ o największym błędzie, a gdy $E_j > 0$ wybieramy $\\alpha_i$ o najmniejszym błędzie.\n",
    "Jeśli przy użyciu $\\alpha_i$ wybranego na podstawie powyższej heurystyki nie może zostać poczyniony postęp, $\\alpha_i$ które umożliwi poczynienie postępu szukane jest pośród nieograniczonych $\\alpha$, a w przypadku porażki pośród ograniczonych $\\alpha$. Oba wspomniane poszukiwania zaczynają się losowym miejscu obu zbiorów.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794dbc2e",
   "metadata": {},
   "source": [
    "### Sczegóły implementacji\n",
    "\n",
    "Klasa SMO inicjalizowana jest przy podaniu znormalizowanej do przedziału <-1, 1> macierzy treningowej i wektora etykiet zawierającego wartości {-1, 1}, parametru funkcji jądrowej gamma, parametru C i opcjonalnej, obliczonej wcześniej macierzy kernel_matrix, takiej, że kernel_matrix[i, j] = kernel_function(x[i], x[j], gamma). \n",
    "Przy inicjalizacji klasy ustawiane są następujące pola:\n",
    "\n",
    "wektor zer alpha, b = 0,\n",
    "\n",
    "eps - tolerancja numeryczna potrzebna do określenia czy dane $\\alpha$ uznać za zmienione w danej iteracji, \n",
    "\n",
    "zbiory bound_alphas (wszystkie alpha), unbound_alphas (pusty),\n",
    "\n",
    "cache błędów - mające przyspieszyć wyznaczanie błędów $E_i$,\n",
    "\n",
    "unbound_err_cache - zbiór potrzebny do wyznaczania heurystycznie wartości potrzebnych w podczas wyboru drugiego $\\alpha$ do optymalizacji,\n",
    "\n",
    "alpha_metadata - tablica zawierająca dane o każdym z $\\alpha$ - czy jest on ograniczony i czy wartość jego błędu jest w cache.\n",
    "\n",
    "Ze względu na fakt, że zbiór danych na którym ma uczyć się algorytm jest relatywnie duży (macierz danych o wymiarach (12000 x 784)) W celu przyspiesznia obliczeń podczas poszukiwania optymalnych parametrów do algorytmu wprowadzona została możliwość obliczenia wcześniej macierzy kernel_matrix i uniknięcia obliczania relatywnie kosztownej obliczeniowo kernel_function podczas uczenia algorytmu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e908e546",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def __init__(self, x, y, c, gamma, km):\n",
    "        self.b = 0\n",
    "        self.alpha = np.zeros((x.shape[0], 1))\n",
    "        self.features = x\n",
    "        self.labels = y.reshape(len(y), 1)\n",
    "        self.c = c\n",
    "        self.gamma = gamma\n",
    "        self.eps = 10**(-3)\n",
    "        self.unbound_alphas = set()\n",
    "        self.bound_alphas = set(range(len(self.alpha)))\n",
    "        self.err_cache = {}\n",
    "        self.unbound_err_cache = {}\n",
    "        self.alpha_metadata = [SMO.AlphaMetadata() for _ in self.alpha]\n",
    "        \n",
    "        if km is None:\n",
    "            self.train_hypothesis = self.no_km_hypothesis\n",
    "        else:\n",
    "            self.kernel_matrix = km\n",
    "            self.train_hypothesis = self.km_hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54036129",
   "metadata": {},
   "source": [
    "Wybór pierwszej wartości $\\alpha$ do optymalizacji realizowany jest w głównej pętli funkcji **train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42424806",
   "metadata": {},
   "outputs": [],
   "source": [
    "    while iters < max_iters and (changed_alphas > 0 or examine_all):\n",
    "                changed_alphas = 0\n",
    "                if examine_all:\n",
    "                    for i in range(self.features.shape[0]):\n",
    "                        changed_alphas += self.examine_example(i, tol)\n",
    "                else:\n",
    "                    set_cpy = copy.copy(self.unbound_alphas)\n",
    "                    for i in set_cpy:\n",
    "                        changed_alphas += self.examine_example(i, tol)\n",
    "\n",
    "                if examine_all:\n",
    "                    examine_all = False\n",
    "                elif changed_alphas == 0:\n",
    "                    examine_all = True\n",
    "                iters += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64b3ad6",
   "metadata": {},
   "source": [
    "Sprawdzenie czy dane $\\alpha_j$ naursza warunki KKT(z podaną jako argument tolerancją) i wybór $\\alpha_i$ realizuje funkcja **examine_example** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9944ebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def examine_example(self, i, tol):\n",
    "        E_i = self.get_error(i)\n",
    "        if (self.labels[i] * E_i < -tol and self.alpha[i] < self.c) or \\\n",
    "                (self.labels[i] * E_i > tol and self.alpha[i] > 0):\n",
    "            if len(self.unbound_err_cache) != 0:\n",
    "                idx = self.choice_cheuristic(i)\n",
    "                if self.take_step(i, idx) == 1:\n",
    "                    return 1\n",
    "\n",
    "            tmp_list = list(self.unbound_alphas)\n",
    "            start = random.randint(0, len(tmp_list))\n",
    "            for j in range(len(tmp_list)):\n",
    "                if self.take_step(i, tmp_list[(j + start) % len(tmp_list)]) == 1:\n",
    "                    return 1\n",
    "\n",
    "            tmp_list = list(self.bound_alphas)\n",
    "            start = random.randint(0, len(tmp_list))\n",
    "            for j in range(len(tmp_list)):\n",
    "                if self.take_step(i, tmp_list[(j + start) % len(tmp_list)]) == 1:\n",
    "                    return 1\n",
    "\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18df78c",
   "metadata": {},
   "source": [
    "Próba optymalizacji obu $\\alpha$ podejmowana jest w funkcji **take_step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838052b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def take_step(self, i, j):\n",
    "        if i == j:\n",
    "            return 0\n",
    "        l, h = self.calculate_constrains(i, j)\n",
    "        if l == h:\n",
    "            return 0\n",
    "        old_a_i = copy.deepcopy(self.alpha[i])\n",
    "        old_a_j = copy.deepcopy(self.alpha[j])\n",
    "\n",
    "        k_ii = self.kernel_function(self.features[i], self.features[i], self.gamma)\n",
    "        k_jj = self.kernel_function(self.features[j], self.features[j], self.gamma)\n",
    "        k_ij = self.kernel_function(self.features[i], self.features[j], self.gamma)\n",
    "\n",
    "        eta = 2*k_ij - k_ii - k_jj\n",
    "\n",
    "        if eta < 0:\n",
    "            new_a_j = self.update_alpha_j(i, j, eta)\n",
    "        else:\n",
    "            Lobj, Hobj = self.objective_function_at_bounds(i, j, k_ii, k_jj, k_ij, l, h)\n",
    "            if Lobj < Hobj - self.eps:\n",
    "                new_a_j = l\n",
    "            elif Lobj > Hobj + self.eps:\n",
    "                new_a_j = h\n",
    "            else:\n",
    "                new_a_j = self.alpha[j]\n",
    "\n",
    "        if abs(self.alpha[j] - new_a_j) < self.eps:\n",
    "            return 0\n",
    "\n",
    "        self.alpha[j] = new_a_j\n",
    "\n",
    "        self.check_idx_bounds(j)\n",
    "\n",
    "        self.alpha[i] += self.labels[i] * self.labels[j] * (old_a_j - self.alpha[j])\n",
    "\n",
    "        self.check_idx_bounds(i)\n",
    "\n",
    "        self.calculate_b(i, j, old_a_i, old_a_j)\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46292e02",
   "metadata": {},
   "source": [
    "Używana powyżej funkcja **check_idx_bounds** usuwa z cache błędy zmienionych $\\alpha$, pilnuje poprawności zbiorów bound_alphas i unbound_alphas oraz tablicy alpha_metadata. Funkcja **update_alpha_j** realizuje obliczenia $(15)$, **calculate_constrains** obliczenia $(9), (1)$, a **self.calculate_b** obliczenia $(18) - (20)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef62476",
   "metadata": {},
   "source": [
    "### SVM rozpoznający wiele klas\n",
    "Klasyfikacja wielu klas odbywa się według podejścia one-vs-rest, tworzona jest oddzielna instancja SVM dla każdej z klas, jako dane dla każdej z nich przekazywana jest pewna część zestawu danych zawierająca wszystkie elementy z etykietą oznaczającą klasę jaka ma być rozpoznawana przez dany SVM oraz taką samą liczbę losowo wybranych elementów z etykietą nie zawierającą tej klasy. Podejście takie zostało wybrane poprzez nie korzystne skalowanie się algorytmu do dużych danych wejściowych i pozwala ono na znaczne przyspieszenie uczenia niewielkim kosztem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88a23ad",
   "metadata": {},
   "source": [
    "### Parametry\n",
    "Parametry jakie należy podać do algorytmu są to : parametr gamma funkcji jądrowej, parametr regularyzacji C oraz tolerancja odnośnie spełnienia warunków KKT. Optymalny zestaw parametrów został wybrany w sposób eksperymentalny poprzez testowanie wyników działania algorytmu dla różnych zestawów parametrów. Testowane zestawy parametrów obejmowały $C$ $\\in$ {10, 5, 1, 0.1, 0.05, 0.01} i $\\gamma$ $\\in$ {10, 100, 1000, 5000, 10000} dla tolerancji $tol$ $\\in$ {0.01, 0.005, 0.001}. Można zaobserowować zależność, że algorytm osiąga największą dokładność dla parametrów $\\gamma$ i $C$ pozostających w stosunku około $\\frac{C}{\\gamma} = \\frac{1}{100}$ i osiąga największą dokładność dla $\\gamma = 100$ i $C = 1$. Można również zauważyć, że czas działania (ilość iteracji) jest odwrotnie proporcjonalny do tolerancji, aczkolwiek podczas testów ustawiona była tolerancja $tol = 0.005$ w celu utrzymania akceptowalnego czasu obliczeń.\n",
    "\n",
    "Dla każdego z SVM (dla każdej z cyfr) zostały użyte te same parametry.\n",
    "\n",
    "### Wyniki Działania \n",
    "#### Najlepsze dopasowane parametry\n",
    "Dla parametrów $C = 1.0, \\quad \\gamma = 100.0$ ***algorytm poprawnie sklasyfikował 98.7% obrazów*** z zestawu testowego.\n",
    "Przy czym każdy z SVM poprawnie sklasyfikował 96-99% danych treningowych. \n",
    "\n",
    "Wizualizacje macierzy $\\alpha \\cdot X$\n",
    "\n",
    "<div class=\"row\", style=\"display: table\">\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"zero_svm_opt.png\" alt=\"zero_svm_opt\" >\n",
    "  </div>\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"one_svm_opt.png\" alt=\"one_svm_opt\">\n",
    "  </div>\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"two_svm_opt.png\" alt=\"two_svm_opt\">\n",
    "  </div>\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"three_svm_opt.png\" alt=\"three_svm_opt\" >\n",
    "  </div>\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"seven_svm_opt.png\" alt=\"seven_svm_opt\">\n",
    "  </div>\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"eight_svm_opt.png\" alt=\"eight_svm_opt\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "#### Porównanie z wynikami dla parametrów mniej optymalnych\n",
    "Dla porównania wynik dla mniej optymalnych parametrów $C = 5.0, \\quad \\gamma = 100.0$ wynosił 32.22%.\n",
    "Przy czym każdy z SVM poprawnie sklasyfikował 53-91% danych treningowych.\n",
    "\n",
    "Wizualizacje macierzy $\\alpha \\cdot X$\n",
    "\n",
    "<div class=\"row\", style=\"display: table\">\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"zero_svm_subopt.png\" alt=\"zero_svm_subopt\" >\n",
    "  </div>\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"one_svm_subopt.png\" alt=\"one_svm_subopt\">\n",
    "  </div>\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"two_svm_subopt.png\" alt=\"two_svm_subopt\">\n",
    "  </div>\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"three_svm_subopt.png\" alt=\"three_svm_subopt\" >\n",
    "  </div>\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"seven_svm_subopt.png\" alt=\"seven_svm_subopt\">\n",
    "  </div>\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"eight_svm_subopt.png\" alt=\"eight_svm_subopt\">\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd56175e",
   "metadata": {},
   "source": [
    "\n",
    "### Źródła\n",
    "1. Burges, C. J. C., \"A Tutorial on Support Vector Machines for Pattern Recognition\" (https://www.di.ens.fr/~mallat/papiers/svmtutorial.pdf)\n",
    "2. Platt, J.C. \"Sequential Minimal Optimization: A Fast Algorithm for Training Support Vector Machines\" (https://web.iitd.ac.in/~sumeet/tr-98-14.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719b6436",
   "metadata": {},
   "source": [
    "## Softmax Regression\n",
    "### Opis algorytmu\n",
    "Softmax regression jest algorytmem będącym generalizacją regresji logistycznej (może być też interpretowany jako sieć neuronowa bez warstw ukrytych ze znormalizowanymi aktywacjami). Uczenie odbywa się poprzez gradientową minimalizację funkcji kosztu \n",
    "$$ J(\\Theta) = - \\sum^m_{i=1} \\sum^K_{k=1} 1\\{y^{(i)} = k\\} log \\frac{exp(\\Theta^{(k)T}x^{(i)})}{\\sum^K_{j=1}exp(\\Theta^{(j)T}x^{(i)})} + \\lambda ||\\Theta||^2 $$, gdzie $\\Theta$ jest wektorem parametrów o wymiarach (n+1, k), gdzie n jest liczbą cech wektora wejściowego, a k liczbą klas i $\\Theta^{(k)}$ oznacza wektor $\\Theta$ dla $k$-tej klasy, a $\\lambda$ jest parametrem określającym regularyzację.\n",
    "\n",
    "Funkcja decyzyjna $h(x)$ zwraca wektor, którego $i$-ty element jest prawdopodobieństwem, że $x$ należy do klasy $i$\n",
    "$$ h(x) = \\frac{1}{\\sum^K_{j=1}exp(\\Theta^{(j)T}x)} \\cdot \\begin{bmatrix} exp(\\Theta^{(1)T}x)  \\\\  \\vdots \\\\  exp(\\Theta^{(K)T}x) \\end{bmatrix} $$\n",
    "\n",
    "A predykcja może być dokonywana jako wybranie największego elementu wektora zwróconego przez $h(x)$\n",
    "\n",
    "### Uczenie\n",
    "Uczenie algorytmu odbywa się metodą gradientową poprzez odejmowanie od $\\Theta$ wektora pochodnych cząstkowych po funkcji kosztu, przesuwając się w stronę minimum globalnego funkcji kosztu. Odbywa się to partiami (mini batch gradient descent). Krok pętli uczącej można zapisać jako: \n",
    "$$ \\Theta -= \\frac{\\alpha}{B} \\cdot \\nabla_{\\Theta}J(\\Theta) $$\n",
    "gdzie $\\alpha$ jest wpółczynnikiem uczenia, a $B$ jest rozmiarem \"partii\" danych (batch),  $\\nabla_{\\Theta}J(\\Theta)$ jest wektorem pochodnych cząstkowych i dla danego $x$ wynosi :\n",
    "$$ \\nabla_{\\Theta}J(\\Theta) = x^T \\cdot (h(x) - y) + \\lambda \\Theta $$ \n",
    "\n",
    "### Szczegóły implementacji\n",
    "Wszystkie obliczenia wykonywane są na wetkorach, więc implementacja mini batch gradient descent wygląda następująco:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254f2ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    " for c in range(iters):\n",
    "            for i in range(0, y.shape[0]):\n",
    "                if i + batch_size < y.shape[0]:\n",
    "                    self.train_batch(x[i:i+batch_size, :], y[i:i+batch_size, :],\n",
    "                                     learning_rate, reg_param, batch_size)\n",
    "                else:\n",
    "                    self.train_batch(x[i:, :].reshape(y.shape[0] - i, x.shape[1]),\n",
    "                                     y[i:, :].reshape(y.shape[0] - i,  self.k),\n",
    "                                     learning_rate, reg_param, y.shape[0] - i)\n",
    "                \n",
    "def train_batch(self, x, y, learning_rate, reg_param, batch_size):\n",
    "        self.Theta -= learning_rate * self.gradient(np.c_[np.ones(x.shape[0]), x], y, reg_param) / y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64837dc1",
   "metadata": {},
   "source": [
    "Do każdego wywołania funkcji **gradient** czy funkcji decyzyjnej przekazywana jest macierz $x$, do której należy dodać wektor jedynek, w celu umożliwienia algorytmowi wprowadzenia bias term do obliczeń. Macierz $\\Theta$ jest inicjalizowana uwzględniając bias term na rozmiar (n+1, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd45f94b",
   "metadata": {},
   "source": [
    "### Parametry\n",
    "Parametry jakie należy podać do algorytmu są to : parametr określający szybkość uczenia alpha oraz parametr określający poziom regularyzacji. Prędkość zbiegania się algorytmu do optymalnego rozwiązania jest uzależniona od parametru $\\alpha$ - jeśli jest on zbyt mały czas działania algorytmu będzie niepotrzebnie wydłużony, zaś jeśli jest on zbyt duży algorytm może nie osiągnąć w ogóle rozwiązania optymalnego. Parametr $\\lambda$ określa jak dobrze algorytm generalizuje w porównaniu do przykładów na których się uczył, dla zbyt dużego $\\lambda$ widoczne będzie zjawisko underfitingu, zaś dla zbyt małego overfitingu.\n",
    "\n",
    "### Wyniki Działania \n",
    "#### Najlepsze dopasowane parametry\n",
    "Dla parametrów $\\alpha = 0.001, \\quad \\lambda = 0.001$ ***algorytm poprawnie sklasyfikował 91.51% obrazów*** z zestawu testowego.\n",
    "\n",
    "Wizualizacje parametrów $\\theta$ algorytrmu\n",
    "<div class=\"row\", style=\"display: table\">\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"zero_softmax.png\" alt=\"zero_softmax\" >\n",
    "  </div>\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"one_softmax.png\" alt=\"one_softmax\">\n",
    "  </div>\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"two_softmax.png\" alt=\"two_softmax\">\n",
    "  </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cce3f8",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "### Opis algorytmu\n",
    "W opisywanej sieci neuronowej wszystkie warstwy są w pełni połączone, a aktywacjami neuronów w poszczególnych warstwach mogą być funkcje \n",
    "$$ sigmoid(x) = \\frac{1}{1 + exp(-x)} $$\n",
    "$$ ReLU(x) = max{0, x} $$\n",
    "\n",
    "Celem optymalizacji jest minimalizacja funkcji kosztu \n",
    "$$ J(w, b) = \\frac{1}{m} \\sum^m_{i=1} \\sum^K_{k=1} [-y_k^{(i)} log (h(x^{(i)})_k) - (1 - y^{(i)}_k) log (1 - (h(x^{(i)})_k))] + \\frac{\\lambda}{2}\\sum^D_{d=1} \\sum^{a_{d}}_l \\sum^{b_{d}}_k (w^{[d]}_{lk})^2 $$, gdzie \n",
    "$ h(x) $ są aktywacjami ostatniej warstwy neuronów, $D$ jest liczbą warstw, a $a_d, b_d$ są rozmiarami macierzy wag dla warstwy $d$, $\\lambda$ jest parametrem regularyzacji\n",
    "\n",
    "Aktywacje ostatniej warstwy ($h(x)$) obliczane są poprzez algorytm propagacji w przód, a predykcja może być dokonywana jako wybranie największego elementu wektora ($h(x)$), uczenie sieci odbywa się przy użyciu algorytmu propagacji w tył.\n",
    "\n",
    "### Propagacja w przód\n",
    "Algorytm propagacji w przód zaczyna swoją pracę na danych wejściowych do sieci i oblicza wartości aktywacji w kolejnych warstwach.\n",
    "Poszukujemy wartości $z, a$ dla każdej z warstw.\n",
    "$$z_i = w_i a_{i-1} + b_i, \\quad a_i = activation_i(z_i)$$, gdzie $w_i$ jest macierzą wag w $i$-tej warstwy, $a_i$ jest wektorem aktywacji w danej warstwie. Zakładamy, że $a_0 = x$\n",
    "\n",
    "### Propagacja w tył\n",
    "Celem propagacji w tył jest wyznaczanie $\\frac{\\partial J}{\\partial w^{[k]}}$ i $\\frac{\\partial J}{\\partial b^{[k]}}$ dla każdej z warstw, żeby w sposób gradientowy aktualizować wagi. Obliczenia należy zacząć od warstwy ostatniej i korzystając z reguły łańcuchowej pochodnych posuwać się w tył  do osiągnięcia pierwszej warstwy.\n",
    "$$ \\frac{\\partial J}{\\partial w^{[k]}} = \\frac{\\partial J}{\\partial z^{[k]}} a^{[k-1]^T}, \\quad \\frac{\\partial J}{\\partial b^{[k]}} = \\frac{\\partial J}{\\partial z^{[k]}} $$\n",
    "\n",
    "Przyjmując oznaczenie $\\delta^{[k]} = \\frac{\\partial J}{\\partial z^{[k]}}$ i $r$ jako liczbę warstw\n",
    "\n",
    "$$\\delta^{[r]} =  \\frac{\\partial J}{\\partial z^{[r]}} = a^{[r]} - y$$\n",
    "$$ \\forall_{k < r} \\ \\delta^{[k]} = (w^{[k+1]^T} \\delta^{[k+1]}) \\odot {activation_k}'(z^{[k]}) $$\n",
    "\n",
    "gdzie ${activation_k}'$ jest pochodną funkcji aktywacji w $k$-tej warstwie, a $ \\odot$ oznacza mnożenie po elementach\n",
    "\n",
    "Można więc podać regułę aktualizacji dla $w, b$ jako \n",
    "$$ w_k \\ -= \\frac{\\alpha}{B} \\delta^{[k]}a^{[k-1]^T} + \\lambda w_k, \\quad b_k \\ -= \\frac{\\alpha}{B}\\delta^{[k]} $$\n",
    "gdzie $\\alpha$ jest wpółczynnikiem uczenia, a $B$ jest rozmiarem \"partii\" danych (batch)\n",
    "\n",
    "### Szczegóły implementacji\n",
    "Poczas inicjalizacji klasy NeuralNet należy podać liczbę neuronów wejściowych, wyjściowych, architekturę warstw ukrytych oraz funkcje aktywacji na poszczególnych warstwach, włączając ostatnią. Wagi inicjalizowane są jako wartości losowe z dystrybucji normalnej o wartości średniej równej 0 i wariancji równej $\\frac{1}{\\sqrt{d}}$, gdzie $d$ jest wielkością warstwy poprzedniej   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876fdeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "   def initialize_weights(self, input_size, layers_layout):\n",
    "        prev_layer_size = input_size\n",
    "        for layer_size in layers_layout:\n",
    "            self.weights.append(np.random.randn(prev_layer_size, layer_size) * np.sqrt(1/prev_layer_size))\n",
    "            prev_layer_size = layer_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7e24d3",
   "metadata": {},
   "source": [
    "Ze względu na wektoryzację kodu propagacji w tył i przód możliwa jest implementacja uczenia przy użyciu mini batch gradient descent przy użyciu tej samej pętli głównej co SoftmaxRegression, z różnicą w funkcji **train batch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42b27c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "  def train_batch(self, x, y, learning_rate, reg_param, batch_size):\n",
    "        self.forward_prop(x)\n",
    "\n",
    "        # backpropagation algorithm\n",
    "        deltas = [0 for _ in range(self.layers_count)]\n",
    "        deltas[-1] = self.activations[-1] - y\n",
    "        for i in range(self.layers_count - 2, -1, -1):\n",
    "            deltas[i] = np.transpose(self.weights[i + 1].dot(np.transpose(deltas[i + 1])))\n",
    "            deltas[i] = np.multiply(deltas[i], self.activation_derivative(self.z[i], i))\n",
    "        #                                                    l2 regularization\n",
    "        self.weights[0] -= (np.transpose(x).dot(deltas[0]) + reg_param * self.weights[0] * batch_size)\\\n",
    "                           * learning_rate/batch_size\n",
    "        self.biases[0] -= np.sum(deltas[0], axis=0).reshape(self.biases[0].shape) * learning_rate/batch_size\n",
    "        for i in range(1, self.layers_count):\n",
    "            #                                                        l2 regularization\n",
    "            dw = np.transpose(self.activations[i-1]).dot(deltas[i]) + reg_param * self.weights[i] * batch_size\n",
    "            self.weights[i] -= dw * learning_rate/batch_size\n",
    "            db = np.sum(deltas[i], axis=0).reshape(self.biases[i].shape)\n",
    "            self.biases[i] -= db * learning_rate/batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b0cc50",
   "metadata": {},
   "source": [
    "Funkcja **forward_prop** realizuje propagację w przód macierzy x "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c92bb2",
   "metadata": {},
   "source": [
    "### Parametry\n",
    "Parametry jakie należy podać do algorytmu są to : architektura warstw ukrytych oraz parametr regularyzacji lambda.\n",
    "Parametr $\\lambda$ określa jak dobrze algorytm generalizuje w porównaniu do przykładów na których się uczył, dla zbyt dużego $\\lambda$ widoczne będzie zjawisko underfitingu, zaś dla zbyt małego overfitingu. \n",
    "\n",
    "Dobór architektury sieci dokonywany jest w sposób eksperymentalny, aczkolwiek można zauważyć pewne zależności: \n",
    "\n",
    "- wraz z liczbą warstw wydłuża się czas uczenia, co nie koniecznie jest skorelowane z lepszymi wynikami,\n",
    "- rozmiary kolejnych warstw powinny maleć - tj. pierwsza warstwa ukryta powinna mieć najwięcej neuronów (acz maksymalnie w okolicy rozmiaru warstwy wejściowej) a ostania najmniej (acz nie mniej niż warstwa wyjściowa),\n",
    "- warstwy mogą również mieć ten sam rozmiar, ale użycie wielu takich samych warstw o rozmiarze mniejszym niż dane wejściowe prowadzi do gorszych wyników niż jedna warstwa. \n",
    "- aktywacja ReLU spisuje się lepiej w sieci wielowarstwowej, zaś sigmoid przy mniejszej liczbie warstw\n",
    "\n",
    "### Wyniki Działania \n",
    "#### Najlepsze dopasowane parametry\n",
    "Dla $\\lambda = 0.001$ i 4 warstw ukrytych po 800, 400, 200, 50 neuronów z aktywacjami ReLU. ***Algorytm poprawnie sklasyfikował 95.43%*** obrazów z zestawu testowego.\n",
    "\n",
    "#### Przykładowa wizualizacja\n",
    "Próbując interpretować wyniki działania sieci neuronowej można spróbować wizualizować jaką wartość zależną od wag mają poszczególne pixele wejściowe w neuronach kolejnych warstw, co może być zrealizowane przez mnożenie kolejnych macierzy wag.\n",
    "Poniższe wizualizacje dotyczą sieci z jedną, 20 neuronową warstwą ukrytą osiągająca 91.2 % poprawnie sklasyfikowanych przypadków spośród danych testowych\n",
    "\n",
    "Warstwa ukryta\n",
    "<div class=\"row\", style=\"display: table\">\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"nn_hidden_a.png\" alt=\"zero_svm_subopt\" >\n",
    "  </div>\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"nn_hidden_b.png\" alt=\"nn_hidden_b\">\n",
    "  </div>\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"nn_hidden_c.png\" alt=\"nn_hidden_c\">\n",
    "  </div>\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"nn_hidden_d.png\" alt=\"nn_hidden_d\" >\n",
    "  </div>\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"nn_hidden_e.png\" alt=\"nn_hidden_e\">\n",
    "  </div>\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"nn_hidden_f.png\" alt=\"nn_hidden_f\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "Warstwa wyjściowa\n",
    "<div class=\"row\", style=\"display: table\">\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"nn_out_a.png\" alt=\"nn_out_a\" >\n",
    "  </div>\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"nn_out_b.png\" alt=\"nn_out_b\">\n",
    "  </div>\n",
    "  <div style=\"width:33%; float: left\">\n",
    "    <img src=\"nn_out_c.png\" alt=\"nn_out_c\">\n",
    "  </div>\n",
    "  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c0244",
   "metadata": {},
   "source": [
    "# Podsumowanie\n",
    "- SVM jest algorytmem relatywnie trudnym w implementacji, źle skalującym się, aczkolwiek jego wyniki są interpretowalne, posiada mało parametrów które należy dostosować i osiąga bardzo dobre wyniki klasyfikacji (przy odpowiednio niskiej tolerancji i przy operowaniu na całym zbiorze danych prawdopodobnie osiągnąłby lepszy wynik niż podany wyżej w opracowaniu)\n",
    "\n",
    "- Regresja softmax jest prostym w implementacji, szybkim i łatwo interpretowalnym algorytmem nie osiągającym wyników porównywalnych do pozostałych dwóch\n",
    "\n",
    "- Sieć neuronowa jest algorytmem wymagającym włożenia dużej ilości pracy w zaprojektowanie odpowiedniej architektury, a jego wyniki są ciężkie w interpretacji. Z drugiej strony osiągając bardzo dobre wyniki klasyfikacji, działa w rozsądnym czasie i relatywnie dobrze się skaluje (przy odpowiedniej architekturze prawdopodobnie algorytm osiągnąłby lepsze wyniki niż podane wyżej w opracowaniu)\n",
    "\n",
    "Algorytm regresji softmax najszybciej znajduje rozwiązanie problemu, sieć neuronowa w różnym, zależnym od architektury, tempie, aczkolwiek zawsze wolniej niż regresja softmax. Czas działania obu tych algorytmów liczony jest w minutach SVM zaś w godzinach ze względu na słabe skalowanie do dużych zbiorów danych. \n",
    "\n",
    "Podsumowując, można więc powiedzieć, że algorytmy SVM i sieci neuronowej znacznie przewyższają regresję softmax w zadaniu klasyfikacji, aczkolwiek są też od niej znacznie bardziej skomplikowane. Wyniki osiągnięte przez sieć neuronową i SVM są ciężkie do porównania, gdyż prawdopodobnie nie został włożony wystarczający wysiłek w zaprojektowanie architektury sieci. Można jednak stwierdzić, że algorytm sieci neuronowej działa znacznie szybciej od SVM, lepiej się skaluje i jest prostszy w implementacji kosztem skomplikowania w dobrze parametrów."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
